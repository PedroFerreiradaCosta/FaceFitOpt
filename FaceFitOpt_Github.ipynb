{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FaceFitOpt_Github.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PedroFerreiradaCosta/FaceFitOpt/blob/master/FaceFitOpt_Github.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7OdKpNfC68Z",
        "colab_type": "code",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "7bab91b8-6fa2-4ce6-bee9-576a44d5c5ad"
      },
      "source": [
        "#@markdown .\n",
        "%%html\n",
        "<marquee style='width: 30%; color: green;'><b>&lt;&lt;&lt; Let's start by pressing the Play button next to 'Face Fit Opt' inside the [ ] on the left &lt;&lt;&lt;</b></marquee>"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<marquee style='width: 30%; color: green;'><b>&lt;&lt;&lt; Let's start by pressing the Play button next to 'Face Fit Opt' inside the [ ] on the left &lt;&lt;&lt;</b></marquee>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkdVmB0wI8wG",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "from IPython.utils import io\n",
        "#@markdown # **Face Fit Opt**\n",
        "import time\n",
        "from IPython.display import display, Javascript, HTML\n",
        "from ipywidgets import widgets, Layout\n",
        "with io.capture_output() as captured:\n",
        "  !pip install bayesian-optimization\n",
        "  %tensorflow_version 1.x\n",
        "  !git clone https://github.com/PedroFerreiradaCosta/stylegan-encoder.git\n",
        "  %load_ext autoreload\n",
        "  %autoreload 2\n",
        "import os\n",
        "os.chdir(\"stylegan-encoder\")\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "import pickle\n",
        "from ipywidgets import widgets\n",
        "import PIL.Image\n",
        "import numpy as np\n",
        "import dnnlib\n",
        "import dnnlib.tflib as tflib\n",
        "import config\n",
        "from encoder.generator_model import Generator\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from IPython.display import clear_output\n",
        "import bayes_opt\n",
        "import tensorflow as tf\n",
        "import warnings\n",
        "from sklearn.gaussian_process.kernels import Matern, WhiteKernel\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "from bayes_opt import BayesianOptimization, UtilityFunction\n",
        "from ipywidgets import interact, interactive, fixed, interact_manual\n",
        "from vis import plot_bo\n",
        "from itertools import product\n",
        "\n",
        "# display(HTML(\"<marquee style='width: 30%; color: green;'><b>&lt;&lt;&lt; Let's start by pressing the Play button inside the [ ] on the left &lt;&lt;&lt;</b></marquee>\"))\n",
        "\n",
        "run = widgets.ToggleButton(\n",
        "    value=False,\n",
        "    description=\"Let's Go!\",\n",
        "    disabled=False,\n",
        "    button_style='success', # 'success', 'info', 'warning', 'danger' or ''\n",
        "    tooltip='Click when ready to start game.',\n",
        "    layout= Layout(border = '1px solid black')\n",
        ")\n",
        "\n",
        "\n",
        "display(run)\n",
        "\n",
        "def run_clicked(obj):\n",
        "    display(HTML(\"<marquee style='width: 30%; color: green;'><b>&lt;&lt;&lt; Wait for camera &lt;&lt;&lt;</b></marquee>\"))\n",
        "    run.close()\n",
        "    main()\n",
        "\n",
        "run.observe(run_clicked, 'value')\n",
        "\n",
        "def generate_image(latent_vector):\n",
        "    latent_vector = latent_vector.reshape((1, 18, 512))\n",
        "    generator.set_dlatents(latent_vector)\n",
        "    img_array = generator.generate_images()[0]\n",
        "    img = PIL.Image.fromarray(img_array, 'RGB')\n",
        "    #return img\n",
        "    return img.resize((256, 256))\n",
        "\n",
        "\n",
        "def move_and_show(latent_vector, direction, coeffs):\n",
        "    fig,ax = plt.subplots(1, len(coeffs), figsize=(15, 10), dpi=80)\n",
        "    for i, coeff in enumerate(coeffs):\n",
        "        new_latent_vector = latent_vector.copy()\n",
        "        new_latent_vector[:8] = (latent_vector + coeff*direction)[:8]\n",
        "        ax[i].imshow(generate_image(new_latent_vector))\n",
        "        ax[i].set_title('Coeff: %0.1f' % coeff)\n",
        "    [x.axis('off') for x in ax]\n",
        "    plt.show()\n",
        "\n",
        "def plot_sampled_face(latent_vector, direction1, direction2, x, y, i):\n",
        "\n",
        "  clear_output(wait=True)\n",
        "  #display(plt.gcf())\n",
        "  plt.figure(figsize=(10,10))\n",
        "  new_latent_vector = latent_vector.copy()\n",
        "  new_latent_vector[:8] = (latent_vector + x*direction1)[:8]\n",
        "  new_latent_vector[:8] = (new_latent_vector + y*direction2)[:8]\n",
        "  plt.imshow(generate_image(new_latent_vector))\n",
        "  plt.title('Iteration: {} of 26'.format(i+1))\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "# Loading already learned latent directions\n",
        "smile_direction = np.load('ffhq_dataset/latent_directions/smile.npy')\n",
        "age_direction = np.load('ffhq_dataset/latent_directions/age.npy')\n",
        "\n",
        "\n",
        "# Create Generator Instance\n",
        "# path to model code and weight\n",
        "path_model = 'https://drive.google.com/uc?id=1I1vyhKJhoQul3ryIrHcTlpYycPAhWooI'\n",
        "\n",
        "#   \"\"\" create tf session \"\"\"\n",
        "yn_CPU_only = False\n",
        "gpu_fraction = 0.5\n",
        "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=gpu_fraction)\n",
        "\n",
        "if yn_CPU_only:\n",
        "    config = tf.ConfigProto(device_count = {'GPU': 0}, allow_soft_placement=True)\n",
        "else:\n",
        "    config = tf.ConfigProto(allow_soft_placement=True, gpu_options=gpu_options)\n",
        "    config.gpu_options.allow_growth = True\n",
        "\n",
        "sess = tf.InteractiveSession(config=config)\n",
        "\n",
        "with io.capture_output() as captured:\n",
        "  try:\n",
        "      with dnnlib.util.open_url(path_model, 'rb') as file:\n",
        "          G, D, Gs = pickle.load(file)\n",
        "  except FileNotFoundError:\n",
        "      print('before running the code, download pre-trained model to project_root/asset_model/')\n",
        "      raise\n",
        "  generator = Generator(Gs, batch_size=1, randomize_noise=False)\n",
        "\n",
        "\n",
        "def main():\n",
        "  clear_output()\n",
        "\n",
        "  os.mkdir('raw_images')\n",
        "  os.mkdir('latent_representations')\n",
        "  os.mkdir('aligned_images')\n",
        "  os.mkdir('generated_images')\n",
        "\n",
        "  ###############################################################################\n",
        "\n",
        "\n",
        "  def take_photo(filename='raw_images/photo.jpg', quality=0.8):\n",
        "    clear_output()\n",
        "    js = Javascript('''\n",
        "      async function takePhoto(quality) {\n",
        "        const div = document.createElement('div');\n",
        "        const capture = document.createElement('button');\n",
        "\n",
        "        capture.style.width = '200px'; // setting the width to 200px\n",
        "        capture.style.height = '50px'; // setting the height to 50px\n",
        "        capture.style.background = 'green'; // setting the background color to green\n",
        "        capture.style.color = 'white'; // setting the color to white\n",
        "        capture.style.fontSize = '20px'; // setting the font size to 20px\n",
        "        capture.textContent = 'Capture';\n",
        "\n",
        "        div.appendChild(capture);\n",
        "\n",
        "        const video = document.createElement('video');\n",
        "        video.style.display = 'block';\n",
        "        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "        document.body.appendChild(div);\n",
        "        div.appendChild(video);\n",
        "        video.srcObject = stream;\n",
        "        await video.play();\n",
        "\n",
        "        // Resize the output to fit the video element.\n",
        "        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "        // Wait for Capture to be clicked.\n",
        "        await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "        const canvas = document.createElement('canvas');\n",
        "        canvas.width = video.videoWidth;\n",
        "        canvas.height = video.videoHeight;\n",
        "        canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "        stream.getVideoTracks()[0].stop();\n",
        "        div.remove();\n",
        "        return canvas.toDataURL('image/jpeg', quality);\n",
        "      }\n",
        "      ''')\n",
        "    display(js)\n",
        "    data = eval_js('takePhoto({})'.format(quality))\n",
        "    binary = b64decode(data.split(',')[1])\n",
        "    with open(filename, 'wb') as f:\n",
        "      f.write(binary)\n",
        "    return filename\n",
        "\n",
        "  print('')  \n",
        "  print(\"Press Capture below to take a photo\")\n",
        "  print(\"Try to avoid accessories like glasses or hats.\")\n",
        "\n",
        "  from IPython.display import Image\n",
        "  try:\n",
        "    filename = take_photo()\n",
        "    \n",
        "  except Exception as err:\n",
        "    # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "    # grant the page permission to access it.\n",
        "    print(str(err))\n",
        "    print('You must have a webcam and grant permission to the program to use it.')\n",
        "    !kill -9 -1\n",
        "\n",
        "  ###############################################################################\n",
        "  with io.capture_output() as captured:\n",
        "    # 1) Extract and align faces from images\n",
        "    !rmdir raw_images/.ipynb_checkpoints/\n",
        "    # Images to be processed should be added to the folder 'raw_images'\n",
        "    !python align_images.py raw_images/ aligned_images/\n",
        "    # if downloading dlib face landmarks takes more than 1/2 min, rerun code\n",
        "  print('')\n",
        "  print('')\n",
        "  display(HTML(\"<marquee style='width: 30%; color: green;'><b>&lt;&lt;&lt; Hello again! Right now the face machine is finding an artificial photo that looks just like yours to play in the *Space Face*. It will do that using Artificial Intelligence. This will take between 5 and 10 minutes, so feel free to go make yourself a cup of tea........................................................................Still around? Good! What you will be asked to do next is rate some faces if they look like you or not. Some will be very similar. Others.... not so much. Remember, there are no wrong answers, just what you feel like its the right rating! The machine also makes mistakes, so dont worry if the faces dont look anything like you. </b></marquee>\"))\n",
        "\n",
        "\n",
        "  # 2) Find latent representation of aligned images\n",
        "  with io.capture_output() as captured:\n",
        "    !python encode_images.py aligned_images/ generated_images/ latent_representations/ --iterations 500\n",
        "\n",
        "  # src_dir - directory with images\n",
        "  # generated_images_dir - directory for storing generated images\n",
        "  # dlatent_dir - directory for storing dlatent representations\n",
        "  # batch_size - df - 1 - for generator and perceptual model\n",
        "  # image_size - df - 256 - Size of images for perceptual model\n",
        "  # lr - df 1 - learning rate for perc. model\n",
        "  # iterations - df - 1000 - opetimizations steps per batch \n",
        "  # randomize_noise-  df - False - add noise to dlatents during optimization\n",
        "\n",
        "  run_bayes(generator) #Runs bayesian optimization on the space created by the image\n",
        "  ###############################################################################\n",
        "\n",
        "def run_bayes(generator):\n",
        "\n",
        "  # Latent on the origin of the Space (0,0)\n",
        "  latent_vector = np.load('latent_representations/photo_01.npy')\n",
        "\n",
        "  ###############################################################################\n",
        "\n",
        "  generator = generator\n",
        "  def f(rating):\n",
        "    optimizer.register(next_point_to_probe, rating)\n",
        "    \n",
        "    return rating\n",
        "\n",
        "  pbounds = {'x': (-1, 1), 'y': (-1, 1)}\n",
        "  optimizer = BayesianOptimization(\n",
        "      f=None,\n",
        "      pbounds=pbounds,\n",
        "      verbose=2,\n",
        "      random_state=42,\n",
        "  )\n",
        "  kernel = 1.0 * Matern(length_scale=0.20, length_scale_bounds=(0.05, 1), nu=2.5)\\\n",
        "          + WhiteKernel(noise_level=50, noise_level_bounds=(1e-10, 0.5))\n",
        "  optimizer.set_gp_params(kernel=kernel)\n",
        "  \n",
        "  utility = UtilityFunction(kind=\"ucb\", kappa=2, xi=0)\n",
        "\n",
        "  ###############################################################################\n",
        "\n",
        "  init_points = 5\n",
        "  n_iter = 21\n",
        "  \n",
        "  def sample_and_register(sample):\n",
        "      print('sample and register: {}'.format(sample))\n",
        "      if sample < init_points:\n",
        "          next_point_to_probe = {'x': np.random.uniform(pbounds['x'][0], pbounds['x'][1]),\n",
        "                                  'y': np.random.uniform(pbounds['y'][0], pbounds['y'][1])}\n",
        "\n",
        "          x, y = next_point_to_probe.values()\n",
        "      else:\n",
        "          next_point_to_probe = optimizer.suggest(utility)\n",
        "          x, y = next_point_to_probe.values()\n",
        "\n",
        "      # Here I show the image generated by the new latent\n",
        "      plot_sampled_face(latent_vector, smile_direction, age_direction, x*2, y*2, sample)\n",
        "\n",
        "      rating_input = widgets.BoundedFloatText(\n",
        "      value=5.0,\n",
        "      min=0,\n",
        "      max=10.0,\n",
        "      step=0.1,\n",
        "      disabled=False\n",
        "      )\n",
        "      print('How much does this image look like you? Rate it in the box below from 0 to 10, 10 being just like you.\\n You can use decimals (e.g. 8.7).\\n')\n",
        "      display(rating_input)\n",
        "\n",
        "      run = widgets.ToggleButton(\n",
        "      value=False,\n",
        "      description=\"Rate!\",\n",
        "      disabled=False,\n",
        "      button_style='success', # 'success', 'info', 'warning', 'danger' or ''\n",
        "      tooltip='Click when you have evaluated the face.',\n",
        "      layout= Layout(border = '1px solid black')\n",
        "      )\n",
        "\n",
        "      display(run)\n",
        "\n",
        "      def run_clicked(obj): # New sample, register and start again\n",
        "        if sample + 1 < init_points + n_iter:\n",
        "          \n",
        "          rating = rating_input.value\n",
        "          optimizer.register(next_point_to_probe, float(rating))\n",
        "          sample_and_register(sample+1)\n",
        "          run.close()\n",
        "          rating_input.close()\n",
        "        else:\n",
        "          end_sample(optimizer, latent_vector)\n",
        "\n",
        "      run.observe(run_clicked, 'value')\n",
        "\n",
        "  sample_and_register(0)\n",
        "\n",
        "def end_sample(optimizer, latent_vector):\n",
        "  maximum, params = optimizer.max.values()\n",
        "  x_max,y_max = params.values()\n",
        "\n",
        "  ###############################################################################\n",
        "\n",
        "  x = np.linspace(-1, 1, 50).reshape(-1, 1)\n",
        "  y = np.linspace(-1, 1, 50).reshape(-1, 1)\n",
        "\n",
        "  x_obs = np.array([[res[\"params\"][\"x\"]] for res in optimizer.res])\n",
        "  y_obs = np.array([[res[\"params\"][\"y\"]] for res in optimizer.res])\n",
        "  z_obs = np.array([res[\"target\"] for res in optimizer.res])\n",
        "\n",
        "  x1x2 = np.array(list(product(x, y)))\n",
        "  X0p, X1p = x1x2[:, 0].reshape(50, 50), x1x2[:, 1].reshape(50, 50)\n",
        "\n",
        "  X = (np.array([x_obs.ravel(), y_obs.ravel()])).T\n",
        "  np.save('values',np.array([x_obs.ravel(), y_obs.ravel(), z_obs.ravel()]).T)\n",
        "  \n",
        "  #optimizer._gp.fit(X, z_obs)\n",
        "  mu, std = optimizer._gp.predict(x1x2.reshape(-1, 2), return_std=True)\n",
        "  np.save('mu',mu)\n",
        "  np.save('std',std)\n",
        "\n",
        "  ###############################################################################\n",
        "\n",
        "  clear_output()\n",
        "\n",
        "  run = widgets.ToggleButton(\n",
        "  value=False,\n",
        "  description=\"Results\",\n",
        "  disabled=False,\n",
        "  button_style='info', # 'success', 'info', 'warning', 'danger' or ''\n",
        "  tooltip='Click to see your results.',\n",
        "  layout= Layout(border = '1px solid black')\n",
        "  )\n",
        "\n",
        "  display(HTML(\"<marquee style='width: 30%; color: green;'><b>You did it! Well done! Do you want to see what your results look like? Click on the button! Also, please consider leaving a star in the Github Repo. Thank you!</b></marquee>\"))\n",
        "\n",
        "  display(run)\n",
        "\n",
        "  def run_clicked(obj): # Clicked to see results\n",
        "      run.close()\n",
        "      clear_output()\n",
        "      plot_result(optimizer, latent_vector)\n",
        "\n",
        "\n",
        "  run.observe(run_clicked, 'value')\n",
        "\n",
        "\n",
        "\n",
        "def plot_result(optimizer, latent_vector):\n",
        "  # #### PLOT RESULTS\n",
        "  from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "  from sklearn.gaussian_process.kernels import Matern, WhiteKernel\n",
        "  x = np.linspace(-1, 1, 50).reshape(-1, 1)\n",
        "  y = np.linspace(-1, 1, 50).reshape(-1, 1)\n",
        "\n",
        "  x_obs = np.array([[res[\"params\"][\"x\"]] for res in optimizer.res])\n",
        "  y_obs = np.array([[res[\"params\"][\"y\"]] for res in optimizer.res])\n",
        "  z_obs = np.array([res[\"target\"] for res in optimizer.res])\n",
        "  x1x2 = np.array(list(product(x, y)))\n",
        "\n",
        "  kernel=2.09**2 * Matern(length_scale=1, nu=2.5) + WhiteKernel(noise_level=0.5)\n",
        "  gpr = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10, optimizer=None)\n",
        "\n",
        "  gpr.fit(np.array([x_obs,y_obs]).reshape(-1,2), z_obs)\n",
        "\n",
        "  mu, std = gpr.predict(x1x2.reshape(-1, 2), return_std=True)\n",
        "\n",
        "  Zmu = np.reshape(mu, (50, 50))\n",
        "  X0p = x1x2[:, 0].reshape(50, 50)\n",
        "  X1p = x1x2[:, 1].reshape(50, 50)\n",
        "  plt.pcolormesh(X0p, X1p, Zmu)\n",
        "  plt.title('Your Face Space')\n",
        "  plt.xlabel('Smile')\n",
        "  plt.ylabel('Age')\n",
        "  plt.xlim([-1,1])\n",
        "  plt.ylim([-1,1])\n",
        "  plt.scatter(0,0,marker='X', c='red')\n",
        "\n",
        "  xymax = np.where(Zmu==Zmu.max()) \n",
        "  xmax = xymax[0][0]\n",
        "  ymax = xymax[1][0]  \n",
        "\n",
        "  plt.scatter(X0p[xmax,0], X1p[0,ymax], marker='X', c='blue')\n",
        "  plt.colorbar\n",
        "  plt.show()\n",
        "  print(' Marked in red is what the computer thinks is the closest face to yours.')\n",
        "  print(' Marked in blue is what you rated to be the closest face to yours.')\n",
        "\n",
        "  run = widgets.ToggleButton(\n",
        "  value=False,\n",
        "  description=\"Faces\",\n",
        "  disabled=False,\n",
        "  button_style='info', # 'success', 'info', 'warning', 'danger' or ''\n",
        "  tooltip='Click to see the highest face.',\n",
        "  layout= Layout(border = '1px solid black')\n",
        "  )\n",
        "\n",
        "  display(HTML(\"<marquee style='width: 40%; color: green;'><b> By clicking on the next button you will see the face you rated highest.</b></marquee>\"))\n",
        "  display(run)\n",
        "\n",
        "  def run_clicked(obj): # Clicked to see results\n",
        "      run.close()\n",
        "      show_face(latent_vector, smile_direction, age_direction,\n",
        "                X0p[xmax,0], X1p[0,ymax])\n",
        "\n",
        "  run.observe(run_clicked, 'value')\n",
        "\n",
        "def show_face(latent_vector, direction1, direction2, x, y):\n",
        "  # Show faces\n",
        "  def plot_final_face(latent_vector, direction1, direction2, x, y):\n",
        "    clear_output(wait=True)\n",
        "    plt.figure(figsize=(10,20))\n",
        "    plt.subplot(121)\n",
        "    plt.title('Your \"artificial\" face')\n",
        "    plt.imshow(generate_image(latent_vector))\n",
        "    new_latent_vector = latent_vector.copy()\n",
        "    new_latent_vector[:8] = (latent_vector + x*direction1)[:8]\n",
        "    new_latent_vector[:8] = (new_latent_vector + y*direction2)[:8]\n",
        "    plt.axis('off')\n",
        "    plt.subplot(122)\n",
        "    plt.title('Face rated the highest')\n",
        "    plt.imshow(generate_image(new_latent_vector))\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "  plot_final_face(latent_vector, smile_direction, age_direction, x*2, y*2)\n",
        "  \n",
        "  if y > 0:\n",
        "    print('You identified yourself {} younger!'.format(y))\n",
        "  if y < 0:\n",
        "    print('You identified yourself {} older!'.format(y))\n",
        "  if x > 0:\n",
        "    print('You identified yourself {} happier!'.format(x))\n",
        "  if x < 0:\n",
        "    print('You identified yourself {} angrier!'.format(x))\n",
        "\n",
        "  display(HTML(\"<marquee style='width: 30%; color: green;'><b> Thank you for playing! To finish, click in the button below. </b></marquee>\"))\n",
        "  run = widgets.ToggleButton(\n",
        "  value=False,\n",
        "  description=\"End\",\n",
        "  disabled=False,\n",
        "  button_style='danger', # 'success', 'info', 'warning', 'danger' or ''\n",
        "  tooltip='Click here to finish the game.',\n",
        "  layout= Layout(border = '1px solid black')\n",
        "  )\n",
        "\n",
        "  display(run)\n",
        "\n",
        "  def run_clicked(obj): # Clicked to see results\n",
        "      run.close()\n",
        "      !kill -9 -1\n",
        "  run.observe(run_clicked, 'value')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7EmSruLwSC8",
        "colab_type": "text"
      },
      "source": [
        "."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAhdRia9wR84",
        "colab_type": "text"
      },
      "source": [
        "."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTrHhHCtwR0O",
        "colab_type": "text"
      },
      "source": [
        "."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuVd0xLGwSSf",
        "colab_type": "text"
      },
      "source": [
        "."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15pEYh0uwRuv",
        "colab_type": "text"
      },
      "source": [
        "."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "343pYbJr_q5U",
        "colab_type": "text"
      },
      "source": [
        "."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3rlA3w8_qsh",
        "colab_type": "text"
      },
      "source": [
        "."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcuBSyAdH9Wr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxgR3HwjIDYN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZnH9h7pwPfB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title To try again, first click play on this cell. {display-mode: \"form\"}\n",
        "\n",
        "!kill -9 -1\n",
        "\n",
        "print('You can now play again the first cell.')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hDFVm27wPYI",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHmcjsCwwO3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPo4bvMNwOzx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWoon12C3MM_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiwxv8Pv3ML6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_O2qeGrUXKx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7B_xK1SBuV3r",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHLpgb7tF2pl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6y3WGoJ_GMy0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7J6xCTqN6ZWd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HwNadku6fJJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGyhFSNo6yDA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0_asN32_ehp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aX7y1EWFPQF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}